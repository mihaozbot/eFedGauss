{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils.utils_dataset import prepare_k_fold_non_iid_dataset, plot_dataset_split, display_dataset_split, prepare_k_fold_federated_dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from utils.utils_train import train_unsupervised, test_model\n",
    "from utils.utils_plots import plot_first_feature_horizontal, save_figure\n",
    "from utils.utils_metrics import calculate_metrics_statistics, calculate_cluster_stats, calculate_unsupervised_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.eGauss_plus import eGAUSSp\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")\n",
    "\n",
    "# Model parameters\n",
    "local_model_params = {\n",
    "    \"feature_dim\": 2,\n",
    "    \"num_classes\": 3,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 2,\n",
    "    \"kappa_join\": 0.5, #to show the effects of the federated learning, this has to be large\n",
    "    \"S_0\": 1e-8,\n",
    "    \"N_r\": 8,\n",
    "    \"c_max\": 10000,\n",
    "    \"device\": device\n",
    "}\n",
    "federated_model_params = {\n",
    "    \"feature_dim\": 2,\n",
    "    \"num_classes\": 3,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 3,\n",
    "    \"kappa_join\": 0.9,\n",
    "    \"S_0\": 1e-8,\n",
    "    \"N_r\": 8,\n",
    "    \"c_max\": 10000,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data as provided\n",
    "\n",
    "z_1_top = 1*np.random.randn(1, 200)\n",
    "z_1 = np.vstack((z_1_top, z_1_top + (0.8 * np.random.randn(1, 200))))\n",
    "z_2_top = np.random.randn(1, 200)\n",
    "z_2 = np.vstack((z_2_top, -z_2_top + (8 + 0.85 * np.random.randn(1, 200))))\n",
    "z_3_top = -1.5 + 0.5 * np.random.randn(1, 200)\n",
    "z_3 = np.vstack((z_3_top, -z_3_top + (4 + 0.5 * np.random.randn(1, 200))))\n",
    "\n",
    "'''\n",
    "z_1_top = 1*np.random.randn(1, 250)\n",
    "z_1 = np.vstack((z_1_top, z_1_top + (0.8 * np.random.randn(1,250))))\n",
    "z_2_top = np.random.randn(1, 100)\n",
    "z_2 = np.vstack((z_2_top, -z_2_top + (8 + 0.85 * np.random.randn(1, 100))))\n",
    "z_3_top = -1.5 + 0.5 * np.random.randn(1, 50)\n",
    "z_3 = np.vstack((z_3_top, -z_3_top + (4 + 0.5 * np.random.randn(1, 50))))\n",
    "'''\n",
    "\n",
    "labels_1 = 0*np.ones((z_1.shape[1],), dtype=np.int32)  # Label 0 for z_1 cluster\n",
    "labels_2 = 1*np.ones((z_2.shape[1],), dtype=np.int32)  # Label 1 for z_2 cluster\n",
    "labels_3 = 2*np.ones((z_3.shape[1],), dtype=np.int32)  # Label 2 for z_3 cluster\n",
    "\n",
    "# Concatenate the data and labels\n",
    "z = np.hstack((z_1, z_2, z_3))\n",
    "labels = np.hstack((labels_1, labels_2, labels_3))\n",
    "\n",
    "# Shuffle the data and labels in the same order\n",
    "indices = np.random.permutation(z.shape[1])\n",
    "data = z[:, indices].transpose()\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = labels\n",
    "\n",
    "num_splits = 3\n",
    "\n",
    "# Define the configurations for the experiments\n",
    "num_clients_options = [1, 3, 5, 10]  # Number of clients\n",
    "data_percentage_options = [0.1, 0.2, 0.33, 1]  # Percentage of data for each client\n",
    "\n",
    "# Define the specific configurations of interest\n",
    "specific_configurations = [\n",
    "    (1, 1), \n",
    "    (3, 0.10), (5, 0.10), (10, 0.10),  # 10% data for 3, 5, and 10 clients\n",
    "    (3, 0.20), (3, 0.33)              # 20% and 33% data for 3 clients\n",
    "]\n",
    "\n",
    "# Placeholder for results\n",
    "experiment_results = []\n",
    "\n",
    "# Number of repetitions for each configuration\n",
    "num_repetitions = 10\n",
    "\n",
    "# Loop over the different configurations\n",
    "for num_clients in num_clients_options:\n",
    "    for data_percentage in data_percentage_options:\n",
    "        if (num_clients, data_percentage) in specific_configurations:\n",
    "            print(f\"\\nExperiment with {num_clients} clients and {data_percentage*100}% data per client\")\n",
    "\n",
    "            # Initialize result containers for this configuration\n",
    "            config_results = {\n",
    "                \"client_clusters\": [],\n",
    "                \"aggregated_clusters\": [],\n",
    "                \"federated_metrics\": [],\n",
    "                \"federated_clusters\": [],\n",
    "                \"num_of_samples\": []\n",
    "            }\n",
    "\n",
    "            for repetition in range(num_repetitions):\n",
    "                print(f\"Repetition {repetition + 1}/{num_repetitions} for {num_clients} clients and {data_percentage*100}% data\")\n",
    "\n",
    "                kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  \n",
    "\n",
    "                # Initialize arrays to track samples per class for each client in each fold\n",
    "                samples_per_class_per_client = np.zeros((num_clients, local_model_params[\"num_classes\"], num_splits))\n",
    "\n",
    "                # Main loop for k-fold cross-validation\n",
    "                #all_client_metrics = [[] for _ in range(num_clients)]\n",
    "                all_client_clusters = [[] for _ in range(num_clients)]\n",
    "                all_agregated_clusters = []\n",
    "                all_federated_metrics = []\n",
    "                all_federated_clusters = []\n",
    "\n",
    "                # K-Fold Cross-Validation\n",
    "                for i_fold, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "                    print(f\"*** Repetition {repetition + 1}/{num_repetitions}. Start of fold {i_fold} for {num_clients} clients and {data_percentage*100}% data per client ***\")\n",
    "\n",
    "                    # Split the data based on the current configuration\n",
    "                    train_data, test_data, all_data = prepare_k_fold_federated_dataset(\n",
    "                        X, y, train_index, test_index, num_clients, data_percentage)\n",
    "                    \n",
    "                    local_models = [eGAUSSp(**local_model_params) for _ in range(num_clients)]\n",
    "                    federated_model = eGAUSSp(**federated_model_params)\n",
    "\n",
    "                    #federated_model.toggle_debugging(True)\n",
    "                    \n",
    "                    #Train the models\n",
    "                    for client_idx, client_model in enumerate(local_models):\n",
    "                        #client_model.toggle_debugging(True)\n",
    "\n",
    "                        # Count the number of samples per class for this client in this fold\n",
    "                        for class_idx in range(client_model.num_classes):\n",
    "                            class_samples = torch.sum(train_data[client_idx][1] == class_idx)\n",
    "                            samples_per_class_per_client[client_idx, class_idx, i_fold] = class_samples\n",
    "\n",
    "                        #unsupervised clustering\n",
    "                        print(f\"Training model for client {client_idx + 1}\")\n",
    "                        train_unsupervised(client_model, train_data[client_idx]) \n",
    "                        \n",
    "                        #Save the number of clusters\n",
    "                        num_client_clusters = torch.sum(client_model.n[:client_model.c] > 1).item()\n",
    "                        print(f\"Number of clusters with multiple samples for Client {client_idx + 1} = {num_client_clusters}\")\n",
    "                        all_client_clusters[client_idx].append(num_client_clusters)\n",
    "\n",
    "                    #Aggregate local models\n",
    "                    for client_idx, client_model in enumerate(local_models):\n",
    "                        federated_model.federal_agent.merge_model_privately(client_model, n_min=1, pred_min=0)\n",
    "                        num_agregated_clusters = torch.sum(federated_model.n[:federated_model.c] > 1).item()\n",
    "                        all_agregated_clusters.append(num_agregated_clusters)\n",
    "\n",
    "                    #Merge the federated model clusters\n",
    "                    federated_model.federal_agent.federated_merging()\n",
    "\n",
    "                    num_federated_clusters = torch.sum(federated_model.n[:federated_model.c] > 1).item()\n",
    "                    print(f\"Number of clusters after merging = {federated_model.c}\")\n",
    "                    all_federated_clusters.append(num_federated_clusters)\n",
    "                    \n",
    "                    #Plot the Aggregated model\n",
    "                    if repetition == num_repetitions-1 and i_fold == (num_splits-1): \n",
    "                        fig = plot_first_feature_horizontal(all_data, model=federated_model, num_sigma=2, N_max=1, title=\"\")  \n",
    "                        \n",
    "                    #Test the federated model\n",
    "                    _,_, cluster_assignment = test_model(federated_model, test_data)\n",
    "                    federated_metrics = calculate_unsupervised_metrics(cluster_assignment.cpu(), test_data)\n",
    "                    all_federated_metrics.append(federated_metrics)\n",
    "                    \n",
    "                # Collect results for this repetition\n",
    "                config_results[\"client_clusters\"].append(all_client_clusters)\n",
    "                config_results[\"aggregated_clusters\"].append(all_agregated_clusters)\n",
    "                config_results[\"federated_metrics\"].append(all_federated_metrics)\n",
    "                config_results[\"federated_clusters\"].append(all_federated_clusters)\n",
    "                config_results[\"num_of_samples\"].append(samples_per_class_per_client)\n",
    "\n",
    "            # After all repetitions, append the summarized results\n",
    "            experiment_results.append({\n",
    "                \"num_clients\": num_clients,\n",
    "                \"data_percentage\": data_percentage,\n",
    "                **config_results\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non IID experiment\n",
    "# Define the specific configurations of interest\n",
    "specific_configurations = [\n",
    "    (3, 0.33), (5, 0.20), (10, 0.10),  # 10% data for 3, 5, and 10 clients\n",
    "]\n",
    "\n",
    "experiment_non_iid_results = []\n",
    "\n",
    "# Loop over the different configurations\n",
    "for num_clients in num_clients_options:\n",
    "    for data_percentage in data_percentage_options:\n",
    "        if (num_clients, data_percentage) in specific_configurations:\n",
    "            print(f\"\\nNon-IID Experiment with {num_clients} clients and {data_percentage*100}% data per client\")\n",
    "\n",
    "            # Initialize result containers for this configuration\n",
    "            config_results = {\n",
    "                \"client_clusters\": [],\n",
    "                \"aggregated_clusters\": [],\n",
    "                \"federated_metrics\": [],\n",
    "                \"federated_clusters\": [],\n",
    "                \"num_of_samples\": []\n",
    "            }\n",
    "\n",
    "            for repetition in range(num_repetitions):\n",
    "                print(f\"Repetition {repetition + 1}/{num_repetitions} for {num_clients} clients and {data_percentage*100}% data\")\n",
    "\n",
    "                # Main loop for k-fold cross-validation\n",
    "                #all_client_metrics = [[] for _ in range(num_clients)]\n",
    "                all_client_clusters = [[] for _ in range(num_clients)]\n",
    "                all_agregated_clusters = []\n",
    "                all_federated_metrics = []\n",
    "                all_federated_clusters = []\n",
    "\n",
    "                # Initialize K-Fold outside the repetition loop\n",
    "                kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  \n",
    "\n",
    "                # Initialize arrays to track samples per class for each client in each fold\n",
    "                samples_per_class_per_client = np.zeros((num_clients, local_model_params[\"num_classes\"], num_splits))\n",
    "\n",
    "                # K-Fold Cross-Validation for each repetition\n",
    "                for i_fold, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "\n",
    "                    # Split the data based on the current configuration\n",
    "                    train_data, test_data, all_data = prepare_k_fold_non_iid_dataset(\n",
    "                        X, y, train_index, test_index, num_clients)\n",
    "                    \n",
    "                    #Create the models\n",
    "                    local_models = [eGAUSSp(**local_model_params) for _ in range(num_clients)]\n",
    "                    federated_model = eGAUSSp(**federated_model_params)\n",
    "                    #federated_model.toggle_debugging(True)\n",
    "                    \n",
    "                    #Train the models\n",
    "                    for client_idx, client_model in enumerate(local_models):\n",
    "                        #client_model.toggle_debugging(True)\n",
    "\n",
    "                        # Count the number of samples per class for this client in this fold\n",
    "                        for class_idx in range(client_model.num_classes):\n",
    "                            class_samples = torch.sum(train_data[client_idx][1] == class_idx)\n",
    "                            samples_per_class_per_client[client_idx, class_idx, i_fold] = class_samples\n",
    "\n",
    "                        #unsupervised clustering\n",
    "                        print(f\"Training model for client {client_idx + 1}\")\n",
    "                        train_unsupervised(client_model, train_data[client_idx]) \n",
    "                        \n",
    "                        #Save the number of clusters\n",
    "                        num_client_clusters = torch.sum(client_model.n[:client_model.c] > 1).item()\n",
    "                        print(f\"Number of clusters with multiple samples for Client {client_idx + 1} = {num_client_clusters}\")\n",
    "                        all_client_clusters[client_idx].append(num_client_clusters)\n",
    "\n",
    "                    #Aggregate local models\n",
    "                    for client_idx, client_model in enumerate(local_models):\n",
    "                        federated_model.federal_agent.merge_model_privately(client_model, n_min=1, pred_min=0)\n",
    "                        num_agregated_clusters = torch.sum(federated_model.n[:federated_model.c] > 1).item()\n",
    "                        all_agregated_clusters.append(num_agregated_clusters)\n",
    "\n",
    "                        #Plot local models\n",
    "                        \n",
    "                        if repetition == (num_repetitions-1) and num_clients == 3 and  data_percentage == 0.33 and i_fold == (num_splits-1):\n",
    "                                \n",
    "                            #Plot the local models\n",
    "                            fig = plot_first_feature_horizontal(train_data[client_idx], model=client_model, num_sigma=2, N_max=1, title=\"\", format=\"%d\")  #f\"Local model {client_idx+1}\"\n",
    "                            save_figure(fig, f\".Images/synthetic_local_model_{client_idx+1}.svg\", \"svg\")\n",
    "                            save_figure(fig, f\".Images/synthetic_local_model_{client_idx+1}.pdf\",\"pdf\")\n",
    "                        \n",
    "\n",
    "                    #Plot the Aggregated model\n",
    "                    if repetition == (num_repetitions-1) and num_clients == 3 and  data_percentage == 0.33 and i_fold == (num_splits-1):\n",
    "                        fig = plot_first_feature_horizontal(all_data, model=federated_model, num_sigma=2, N_max=0, title=\"\", format=\"%.0f\")   \n",
    "                        save_figure(fig, \".Images/synthetic_federated_pre_merge.svg\",\"svg\")\n",
    "                        save_figure(fig, \".Images/synthetic_federated_pre_merge.pdf\",\"pdf\")\n",
    "                    \n",
    "\n",
    "                    #Merge the federated model clusters\n",
    "                    #print(f\"\\nNumber of clusters after transfer = {federated_model.c}\")\n",
    "                    federated_model.federal_agent.federated_merging()\n",
    "                    num_federated_clusters = torch.sum(federated_model.n[:federated_model.c] > 1).item()\n",
    "                    print(f\"Number of clusters after merging = {federated_model.c}\")\n",
    "                    all_federated_clusters.append(num_federated_clusters)\n",
    "                    \n",
    "                    #Plot the Aggregated model\n",
    "                    if repetition == (num_repetitions-1) and num_clients == 3 and  data_percentage == 0.33 and i_fold == (num_splits-1):\n",
    "                        fig = plot_first_feature_horizontal(all_data, model=federated_model, num_sigma=2, N_max=0, title=\"\", format=\"%.0f\")   \n",
    "                        save_figure(fig, \".Images/synthetic_federated.svg\",\"svg\")\n",
    "                        save_figure(fig, \".Images/synthetic_federated.pdf\",\"pdf\")\n",
    "                        \n",
    "                    #Test the federated model\n",
    "                    _,_, cluster_assignment = test_model(federated_model, test_data)\n",
    "                    federated_metrics = calculate_unsupervised_metrics(cluster_assignment.cpu(), test_data)\n",
    "                    all_federated_metrics.append(federated_metrics)\n",
    "\n",
    "                # Collect results for this repetition\n",
    "                config_results[\"client_clusters\"].append(all_client_clusters)\n",
    "                config_results[\"aggregated_clusters\"].append(all_agregated_clusters)\n",
    "                config_results[\"federated_metrics\"].append(all_federated_metrics)\n",
    "                config_results[\"federated_clusters\"].append(all_federated_clusters)\n",
    "                config_results[\"num_of_samples\"].append(samples_per_class_per_client)\n",
    "\n",
    "            # After all repetitions, append the summarized results\n",
    "            experiment_non_iid_results.append({\n",
    "                \"num_clients\": num_clients,\n",
    "                \"data_percentage\": data_percentage,\n",
    "                **config_results\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aditional plots of the data\n",
    "display_dataset_split(train_data, test_data)\n",
    "fig = plot_dataset_split(train_data, test_data)\n",
    "save_figure(fig, \"Images/synthetic_data_distribution.svg\",\"svg\")\n",
    "save_figure(fig, \"Images/synthetic_data_distribution.pdf\",\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LaTeX table header and footer\n",
    "table_header = r'''\\begin{table}[ht]\n",
    "\\centering\n",
    "\\setlength{\\tabcolsep}{3pt}\n",
    "\\scriptsize\n",
    "\\caption{Unsupervised Clustering for Different Client Data Distributions}\n",
    "\\begin{tabular}{lcccccc}\n",
    "\\toprule\n",
    "\\textbf{\\#Clients/Data}&\\textbf{\\#Local$\\downarrow$}&\\textbf{\\#Aggre.$\\downarrow$}&\\textbf{\\#Fed.$\\downarrow$}&\\textbf{S$\\uparrow$}&\\textbf{ARI$\\uparrow$}&\\textbf{V$\\uparrow$}\\\\ \n",
    "\\midrule\n",
    "'''\n",
    "\n",
    "\n",
    "def format_row(num_clients, data_percentage, results_list, best_values):\n",
    "    # Function to format a metric with highlighting if it's the best\n",
    "    def format_metric(metric_value, metric_name):\n",
    "        if metric_value == best_values[metric_name]:\n",
    "            return r\"\\textbf{\" + f\"{metric_value}\" + \"}\"\n",
    "        else:\n",
    "            return f\"{metric_value}\"\n",
    "\n",
    "    # Check if results_list contains only one element\n",
    "    results = results_list[0]\n",
    "\n",
    "    # Use the metrics and cluster stats from this single result\n",
    "    avg_std_fed_metrics = calculate_metrics_statistics(results['federated_metrics'])\n",
    "\n",
    "    silhouette_score = format_metric(avg_std_fed_metrics[\"silhouette_score\"], \"silhouette_score\")\n",
    "    ari_score = format_metric(avg_std_fed_metrics[\"adjusted_rand_score\"], \"ari_score\")\n",
    "    v_measure_score = format_metric(avg_std_fed_metrics['v_measure_score'], \"v_measure_score\")\n",
    "\n",
    "    client_clusters = [cluster for client in results['client_clusters'] for cluster in client]\n",
    "    local_clusters, std_local_clusters = calculate_cluster_stats(client_clusters)\n",
    "\n",
    "    aggre_clusters, std_aggre_clusters = calculate_cluster_stats(results['aggregated_clusters'])\n",
    "    fed_clusters, std_fed_clusters = calculate_cluster_stats(results['federated_clusters'])\n",
    "\n",
    "    # Format cluster data\n",
    "    local_clusters_str = f\"{local_clusters:.1f}±{std_local_clusters:.1f}\"\n",
    "    aggre_clusters_str = f\"{aggre_clusters:.1f}±{std_aggre_clusters:.1f}\"\n",
    "    fed_clusters_str = f\"{fed_clusters:.1f}±{std_fed_clusters:.1f}\"\n",
    "\n",
    "    # Compute average number of samples\n",
    "    samples = f\"{int(np.mean(results['num_of_samples'])):d}\"\n",
    "\n",
    "    # Format and return the row string\n",
    "    return f\"{num_clients}/{int(data_percentage * 100)}\\%({samples})&{local_clusters_str}&{aggre_clusters_str}&{fed_clusters_str}&{silhouette_score}&{ari_score}&{v_measure_score}\\\\\\\\\"\n",
    "\n",
    "def generate_table_rows(experiments, part_filter):\n",
    "    # Collect all metrics for determining the best values\n",
    "    metrics_data = {\n",
    "        \"silhouette_score\": [],\n",
    "        \"ari_score\": [],\n",
    "        \"v_measure_score\": [],\n",
    "    }\n",
    "\n",
    "    # Initialize a dictionary to group results by configuration\n",
    "    grouped_results = {}\n",
    "\n",
    "    # Group results by configuration and aggregate metrics\n",
    "    for config in experiments:\n",
    "        if part_filter(config):\n",
    "            config_key = (config['num_clients'], config['data_percentage'])\n",
    "            if config_key not in grouped_results:\n",
    "                grouped_results[config_key] = []\n",
    "            grouped_results[config_key].append(config)\n",
    "\n",
    "            # Aggregate metrics for determining the best values\n",
    "            avg_std_fed_metrics = calculate_metrics_statistics(config['federated_metrics'])\n",
    "            metrics_data[\"silhouette_score\"].append(avg_std_fed_metrics[\"silhouette_score\"])\n",
    "            metrics_data[\"ari_score\"].append(avg_std_fed_metrics[\"adjusted_rand_score\"])\n",
    "            metrics_data[\"v_measure_score\"].append(avg_std_fed_metrics['v_measure_score'])\n",
    "\n",
    "    # Determine best values for each metric\n",
    "    best_values = {metric: max(values) for metric, values in metrics_data.items()}\n",
    "\n",
    "    # Generate rows with highlighting\n",
    "    table_rows = \"\"\n",
    "    for (num_clients, data_percentage), configs in grouped_results.items():\n",
    "        table_rows += format_row(num_clients, data_percentage, configs, best_values) + \"\\n\"\n",
    "\n",
    "    return table_rows\n",
    "\n",
    "# Define filters for each part of the table\n",
    "def is_part0(config):\n",
    "    # Part 1: Experiments with data_percentage of 0.1\n",
    "    return config['data_percentage'] == 1\n",
    "\n",
    "# Define filters for each part of the table\n",
    "def is_part1(config):\n",
    "    # Part 1: Experiments with data_percentage of 0.1\n",
    "    return config['data_percentage'] == 0.1\n",
    "\n",
    "def is_part2(config):\n",
    "    # Part 2: Experiments with 3 clients\n",
    "    return config['num_clients'] == 3\n",
    "\n",
    "def is_part3(config):\n",
    "    \"\"\"Check if the given configuration matches any in the non-IID experiment results.\"\"\"\n",
    "    return True\n",
    "\n",
    "# Define the table footer\n",
    "table_footer = r'''\\bottomrule\n",
    "\\multicolumn{7}{p{0.95\\linewidth}}{\\tiny\\textbf{Note:} The first column displays the number of clients, available data as a percentage of the entire training dataset, and the actual number of samples. The number symbol (\\#) denotes the count of local (\\#Local), aggregated (\\#Aggre.), and federated (\\#Fed.) clusters. Clustering evaluation metrics used in the table include the Silhouette score (S), Adjusted Rand Index (ARI), and V-Measure (V).}\n",
    "\\end{tabular}\n",
    "\\label{tab:unsupervised_metrics}\n",
    "\\end{table}'''\n",
    "\n",
    "# Create rows for each part\n",
    "part0_rows = generate_table_rows(experiment_results, is_part0)\n",
    "part1_rows = r'''\\midrule\n",
    "\\multicolumn{7}{l}{\\textbf{Experiment 1: Influence of Number of Clients with Equal Data Size}} \\\\\n",
    "''' + generate_table_rows(experiment_results, is_part1)\n",
    "part2_rows = r'''\\midrule\n",
    "\\multicolumn{7}{l}{\\textbf{Experiment 2: Influence of Data Percentage per Client}} \\\\\n",
    "''' + generate_table_rows(experiment_results, is_part2)\n",
    "part3_rows = r'''\\midrule\n",
    "\\multicolumn{7}{l}{\\textbf{Experiment 3: Influence of Number of Clients with Non-IID Data}} \\\\\n",
    "''' + generate_table_rows(experiment_non_iid_results, is_part3)\n",
    "\n",
    "# Combine and output the final LaTeX table\n",
    "latex_table = table_header + part0_rows + part1_rows + part2_rows + part3_rows + table_footer\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evolver310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
