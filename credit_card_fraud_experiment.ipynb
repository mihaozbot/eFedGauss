{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihao\\AppData\\Local\\Temp\\ipykernel_4792\\1726286932.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from utils.utils_train import train_supervised, train_models_in_threads, test_model_in_batches\n",
    "from utils.utils_plots import plot_interesting_features, plot_metric_data, save_figure, plot_cluster_data\n",
    "from utils.utils_dataset import prepare_dataset, balance_data_for_clients\n",
    "from utils.utils_dataset import display_dataset_split\n",
    "from utils.utils_metrics import calculate_metrics, plot_confusion_matrix, calculate_roc_auc\n",
    "import threading\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.eFedGauss import eFedGauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1           58.862440\n",
      "V2           94.773457\n",
      "V3           57.708148\n",
      "V4           22.558515\n",
      "V5          148.544973\n",
      "V6           99.462131\n",
      "V7          164.146736\n",
      "V8           93.223927\n",
      "V9           29.029061\n",
      "V10          48.333399\n",
      "V11          16.816387\n",
      "V12          26.532107\n",
      "V13          12.918764\n",
      "V14          29.741092\n",
      "V15          13.376686\n",
      "V16          31.444966\n",
      "V17          34.416326\n",
      "V18          14.539815\n",
      "V19          12.805499\n",
      "V20          93.918625\n",
      "V21          62.033221\n",
      "V22          21.436234\n",
      "V23          67.336147\n",
      "V24           7.421176\n",
      "V25          17.814986\n",
      "V26           6.121896\n",
      "V27          54.177877\n",
      "V28          49.277892\n",
      "Amount    25691.160000\n",
      "Class         1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'creditcard.csv' #Can be downloaded from https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download\n",
    "data = pd.read_csv(file_path)\n",
    "feature_dim = 29\n",
    "\n",
    "# Remove the first dimension/column\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "\n",
    "# Compute the ranges\n",
    "ranges = data.max() - data.min()\n",
    "\n",
    "# Display the ranges\n",
    "print(ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(f\"{torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #torch.device(\"cpu\") #\n",
    "\n",
    "if device == torch.device(\"cpu\"):\n",
    "    \n",
    "    # Set the number of threads to the number of CPU cores\n",
    "    num_cores = os.cpu_count()\n",
    "    torch.set_num_threads(num_cores)\n",
    "    \n",
    "    # Verify the change\n",
    "    print(f\"Number of threads set for PyTorch: {torch.get_num_threads()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment to determine best settings\n",
    "flag_settings_experiment = 0\n",
    "if flag_settings_experiment:\n",
    "\n",
    "    num_clients = 1\n",
    "\n",
    "    # Define the range of values for each parameter\n",
    "    num_sigma_values = [5, 10, 15, 20]\n",
    "    kappa_join_values = [0.3, 0.5, 0.8]\n",
    "    N_r_values = [10, 20, 30]\n",
    "\n",
    "    # Total number of experiments\n",
    "    total_experiments = len(num_sigma_values) * len(kappa_join_values) * len(N_r_values)\n",
    "    completed_experiments = 0\n",
    "\n",
    "    # Define other parameters and data setup\n",
    "    local_model_params = {\n",
    "        \"feature_dim\": feature_dim,\n",
    "        \"num_classes\": 2,\n",
    "        \"kappa_n\": 1,\n",
    "        \"S_0\": 1e-10,\n",
    "        \"c_max\": 100,\n",
    "        \"num_samples\": 200, \n",
    "        \"device\": device  # Make sure 'device' is defined\n",
    "    }\n",
    "\n",
    "    # Placeholder for the best parameters and best score\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "\n",
    "    # List to store all results\n",
    "    results = []\n",
    "\n",
    "    # Function to write data to a file\n",
    "    def write_to_file(file_path, data, mode='a'):\n",
    "        with open(file_path, mode) as file:\n",
    "            file.write(data + \"\\n\")\n",
    "\n",
    "    # Prepare the dataset\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    client_train_unbalanced, test_data, all_data = prepare_dataset(X, y, num_clients)\n",
    "    client_train = balance_data_for_clients(client_raw_data=client_train_unbalanced, balance=[\"random\"], local_models=None, round=1)\n",
    "    \n",
    "    # Initialize a lock and a shared variable for progress tracking\n",
    "    lock = threading.Lock()\n",
    "    completed_experiments = 0\n",
    "    total_experiments = len(num_sigma_values) * len(kappa_join_values) * len(N_r_values)\n",
    "\n",
    "    # Function to execute model training and evaluation\n",
    "    def train_evaluate_model(params):\n",
    "        global completed_experiments\n",
    "        \n",
    "        num_sigma, kappa_join, N_r = params\n",
    "        local_model_params.update({\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r})\n",
    "\n",
    "        local_model = eFedGauss(**local_model_params)\n",
    "        train_supervised(local_model, client_train[0])\n",
    "\n",
    "        _, pred_max, _ = test_model_in_batches(local_model, test_data, batch_size = 1000)\n",
    "        metrics = calculate_metrics(pred_max, test_data, weight=\"binary\")\n",
    "\n",
    "        result_str = f\"num_sigma:{num_sigma}, kappa_join:{kappa_join}, N_r:{N_r}, f1_score:{metrics['f1_score']}, precission:{metrics['precision']}, recall:{metrics['recall']}\"\n",
    "        print(result_str)\n",
    "        write_to_file(\"experiment_results.txt\", result_str)  # Write results to file\n",
    "        \n",
    "        # Update progress\n",
    "        with lock:\n",
    "            completed_experiments += 1\n",
    "            progress = (completed_experiments / total_experiments) * 100\n",
    "            print(f\"Progress: {completed_experiments}/{total_experiments} ({progress:.2f}%)\")\n",
    "\n",
    "        return {\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r, \"f1_score\": metrics[\"f1_score\"], \"precission\": metrics[\"precision\"], \"recall\": metrics[\"recall\"]}\n",
    "        \n",
    "\n",
    "    # Write initial setup data to file\n",
    "    initial_setup_str = f\"Initial Setup: num_clients={num_clients}, num_sigma_values={num_sigma_values}, kappa_join_values={kappa_join_values}, N_r_values={N_r_values}\"\n",
    "    write_to_file(\"experiment_results.txt\", initial_setup_str, mode='w')  # 'w' to overwrite if exists\n",
    "\n",
    "    # Using ThreadPoolExecutor to run in multiple threads\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        param_combinations = list(itertools.product(num_sigma_values, kappa_join_values, N_r_values))\n",
    "        results = list(executor.map(train_evaluate_model, param_combinations))\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(file_path, data, mode='a'):\n",
    "    with open(file_path, mode) as file:\n",
    "        file.write(data + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run one federated learning experiment\n",
    "def run_individual_experiment(federated_model_params, local_model_params, num_clients, num_rounds, client_raw_train, test_data, balance_techniques, test_clients=True):\n",
    "\n",
    "    # Initialize a model for each client\n",
    "    local_models = [eFedGauss(**local_model_params) for _ in range(num_clients)]\n",
    "    federated_model = eFedGauss(**federated_model_params)\n",
    "\n",
    "    # Initialize a list to store the metrics for each round\n",
    "    round_metrics = []\n",
    "    result_file = \"experiment_results.txt\"\n",
    "    client_train = []\n",
    "    for round in range(num_rounds):\n",
    "        start = time.time()\n",
    "\n",
    "        print(f\"--- Communication Round {round + 1} ---\")\n",
    "        round_info = f\"--- Communication Round {round + 1} ---\\n\"\n",
    "        \n",
    "        #Undersample the training dataset\n",
    "        client_train = balance_data_for_clients(client_raw_data=client_raw_train, balance_techniques=balance_techniques, local_models=local_models, round=round)\n",
    "        display_dataset_split(client_train, test_data)\n",
    "        \n",
    "        # Train local models\n",
    "        if device == torch.device(\"cpu\"):\n",
    "            for local_model, client_data in zip(local_models, client_train):\n",
    "                train_supervised(local_model, client_data)\n",
    "\n",
    "                print(f\"Number of local model clusters = {sum(local_model.n[0:local_model.c]> local_model.kappa_n)}\")\n",
    "        else:        \n",
    "            train_models_in_threads(local_models, client_train)\n",
    "\n",
    "        #federated_model.age += torch.sum(federated_model.n_glo)*torch.ones_like(federated_model.age)\n",
    "        # Update federated model with local models\n",
    "        for client_idx, _ in enumerate(local_models):\n",
    "            \n",
    "            #Print the number of local clusters\n",
    "            print(f\"\\n Updating agreggated model with client {client_idx + 1}\")\n",
    "            print(f\"Num of samples in global statistics {sum(local_models[client_idx].n_glo)}\")\n",
    "            print(f\"Number of local model clusters = {sum(local_models[client_idx].n[0:local_models[client_idx].c] > 0)}\")\n",
    "            \n",
    "            # Merge local model before transfer to the federated model\n",
    "            local_models[client_idx].federal_agent.federated_merging()\n",
    "\n",
    "            federated_model.federal_agent.merge_model_privately(local_models[client_idx], local_models[client_idx].kappa_n, pred_min = 0)\n",
    "            federated_model.federal_agent.federated_merging()\n",
    "            \n",
    "            print(f\"Federated clusters after merging = {sum(federated_model.n[0:federated_model.c]> federated_model.kappa_n)}\")\n",
    "                \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Evaluate federated model\n",
    "        def evaluate_federated_model(federated_model, test_data, round, fed_evaluation_results):\n",
    "            \n",
    "            # Evaluate federated model and store results in fed_evaluation_results\n",
    "            fed_scores, fed_pred, _ = test_model_in_batches(federated_model, test_data, batch_size=1000)\n",
    "            fed_binary = calculate_metrics(fed_pred, test_data, \"binary\")\n",
    "            fed_roc_auc = calculate_roc_auc(fed_scores, test_data)\n",
    "\n",
    "            # Store the results in the shared dictionary\n",
    "            fed_evaluation_results['binary'] = fed_binary\n",
    "            fed_evaluation_results['roc_auc'] = fed_roc_auc\n",
    "\n",
    "            # Plot federated model\n",
    "            if round in [29, 30, 31]:\n",
    "                plot_confusion_matrix(fed_pred, test_data)\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "        # Return Federated Model to the Clients (end evaluate local models on test data)\n",
    "        def return_to_client(client_idx, federated_model, test_data, test_clients, client_metrics, local_models):\n",
    "            print(f\"Returning updated model to client {client_idx + 1}\")\n",
    "\n",
    "            # Access and update the client model using its index\n",
    "            local_models[client_idx].federal_agent.merge_model_privately(federated_model, 0, pred_min=0)\n",
    "            local_models[client_idx].federal_agent.federated_merging()\n",
    "\n",
    "            if test_clients:\n",
    "                \n",
    "                # Calculate and collect metrics for each client model\n",
    "                _, client_pred, _ = test_model_in_batches(local_models[client_idx], test_data, batch_size=500)\n",
    "                client_binary = calculate_metrics(client_pred, test_data, \"binary\")\n",
    "                \n",
    "                print(f\"Test Metrics client {client_idx} after merge: {client_binary}\")\n",
    "                \n",
    "                # Update client metrics\n",
    "                with threading.Lock():  # Ensure thread-safe operation\n",
    "                    client_metrics.append({\n",
    "                        'client_idx': client_idx,\n",
    "                        'binary': client_binary,\n",
    "                            'clusters': sum(local_models[client_idx].n[0:local_models[client_idx].c].cpu()> 0)\n",
    "                        })\n",
    "            \n",
    "            # local_models[client_idx].score = torch.ones_like(local_models[client_idx].score) # Evaluation score\n",
    "            local_models[client_idx].num_pred = torch.ones_like(local_models[client_idx].num_pred)\n",
    "            local_models[client_idx].age = torch.ones_like(local_models[client_idx].age)\n",
    "\n",
    "            # Reset local model data, this is required else the number of samples exponentially increases\n",
    "            with torch.no_grad():    \n",
    "                local_models[client_idx].S.data /= torch.min(local_models[client_idx].n[:local_models[client_idx].c].data.clone())\n",
    "                local_models[client_idx].n.data /= torch.min(local_models[client_idx].n[:local_models[client_idx].c].data.clone())\n",
    "                local_models[client_idx].S_glo.data /= torch.sum(local_models[client_idx].n_glo.data.clone()).unsqueeze(-1)\n",
    "                local_models[client_idx].n_glo.data = torch.ones_like(local_models[client_idx].n_glo)\n",
    "        \n",
    "        # Start the federated model evaluation in a separate thread\n",
    "        fed_evaluation_results = {}               # Shared dictionary for federated model evaluation results\n",
    "        fed_evaluation_thread = threading.Thread(target=evaluate_federated_model, args=(federated_model, test_data, round, fed_evaluation_results))\n",
    "        fed_evaluation_thread.start()\n",
    "\n",
    "        # Update client models in separate threads as before\n",
    "        threads = []\n",
    "        client_metrics = []  # Shared resource, ensure thread-safe access\n",
    "        for client_idx, client_model in enumerate(local_models):\n",
    "            thread = threading.Thread(target=return_to_client, args=(client_idx, federated_model, test_data, test_clients, client_metrics, local_models))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "\n",
    "        # Wait for all threads (including federated model evaluation) to complete\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        fed_evaluation_thread.join()\n",
    "        \n",
    "        # Reset federated model number of samples, required\n",
    "        with torch.no_grad():     \n",
    "            federated_model.S[:federated_model.c].data /= torch.min(federated_model.n[:federated_model.c].data.clone())\n",
    "            federated_model.n[:federated_model.c].data /= torch.min(federated_model.n[:federated_model.c].data.clone())\n",
    "            federated_model.S_glo.data /= torch.sum(federated_model.n_glo).unsqueeze(-1)\n",
    "            federated_model.n_glo.data = torch.ones_like(federated_model.n_glo)\n",
    "        \n",
    "        # One more pass of the merging mechanism, possible redundant\n",
    "        #federated_model.federal_agent.federated_merging()\n",
    "        \n",
    "        # Print and write round information to file\n",
    "        round_info = f\"--- End of Round {round + 1} ---\\n\"\n",
    "        print(round_info)\n",
    "\n",
    "        round_metrics.append({\n",
    "            'round': round + 1,\n",
    "            'federated_model': {\n",
    "                'clusters': sum(federated_model.n[0:federated_model.c].cpu() > federated_model.kappa_n),\n",
    "                'binary': fed_evaluation_results['binary'],\n",
    "                'roc_auc': fed_evaluation_results['roc_auc']\n",
    "            },\n",
    "            'client_metrics': client_metrics\n",
    "        })\n",
    "        \n",
    "        # Plot features for the current round\n",
    "        plt.close('all')  # Close all existing plots to free up memory\n",
    "        if 0:\n",
    "            #fig1 = plot_interesting_features(client_train[0], model=federated_model, num_sigma=federated_model.num_sigma, N_max=federated_model.kappa_n)   \n",
    "            #save_figure(fig1, \"./Images/credit_fraud_clusters\", format='pdf')\n",
    "            fig2 = plot_interesting_features(client_train[0], model=federated_model, num_sigma=2, N_max=federated_model.kappa_n)   \n",
    "            save_figure(fig2, \".Images/credit_fraud_samples.pdf\", format='pdf')\n",
    "\n",
    "        # Iterate over each round's metrics and write to file\n",
    "        for metric in round_metrics:\n",
    "            metric_info = f\"Round {metric['round']}: Metrics: {metric['federated_model']['binary']}, ROC AUC: {metric['federated_model']['roc_auc']}\\n\"\n",
    "            print(metric_info)  # Print each round's metrics\n",
    "            try:\n",
    "                write_to_file(result_file, metric_info)  # Write to file\n",
    "            except:\n",
    "                print(\"Could not write to file.\")\n",
    "                pass\n",
    "\n",
    "        # Save the experiments\n",
    "        experiment_file = f\".Results/mid_experiment_{federated_model_params['num_sigma']}_{int(federated_model_params['kappa_join']*10)}_{federated_model_params['N_r']}_{num_clients}_{len(balance_techniques)}_{federated_model_params['c_max']}.pth\"\n",
    "        torch.save(round_metrics, experiment_file)\n",
    "        print(f\"Saved experiment to {experiment_file}\")\n",
    "        print(f\"Round time was {(time.time() - start):.1f}s\")\n",
    "\n",
    "    # After all rounds\n",
    "    final_info = \"All Rounds Completed. Metrics Collected:\\n\"\n",
    "    print(final_info)\n",
    "\n",
    "    # Iterate over each round's metrics and write to file\n",
    "    for metric in round_metrics:\n",
    "        metric_info = f\"Round {metric['round']}: \"\n",
    "        metric_info += f\"Federated Model - Clusters: {metric['federated_model']['clusters']}, \"\n",
    "        metric_info += f\"Binary Metrics: {metric['federated_model']['binary']}, ROC AUC: {metric['federated_model']['roc_auc']}\\n\"\n",
    "\n",
    "        for client_metric in metric['client_metrics']:\n",
    "            metric_info += f\"Client {client_metric['client_idx']} - Binary: {client_metric['binary']}\\n\"\n",
    "\n",
    "        print(metric_info)  # Print each round's metrics\n",
    "\n",
    "    return round_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of values for each parameter\n",
    "num_sigma_values = [10, 15, 20]\n",
    "kappa_join_values = [0.3, 0.4, 0.5, 0.8, 1, 2]\n",
    "N_r_values = [15, 20, 25, 30]\n",
    "proportion = [5, 3, 1]\n",
    "\n",
    "# List of client counts and data configuration indices\n",
    "client_counts = [3]\n",
    "data_config_indices = [1]  # Replace with your actual data configuration indices\n",
    "\n",
    "# Number of communication rounds\n",
    "num_rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiments(data, client_counts, federated_model_params, local_model_params, num_rounds, proportions, flag_profiler=False, flag_test_clients=False):\n",
    "    experiments = []\n",
    "    results_dir = \".Results\"  # Directory to save the results\n",
    "    os.makedirs(results_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "    for num_clients in client_counts:\n",
    "        for proportion in proportions:\n",
    "\n",
    "            print(f'\\n *** Experiment details ***:\\n' \n",
    "            f'  - Number of Clients: {num_clients}\\n' \n",
    "            f'  - Number of Rounds: {num_rounds}\\n'\n",
    "            f'  - Number of Clusters: {federated_model_params[\"c_max\"]}\\n'\n",
    "            f'  - Data dristribution proportions: {proportion}\\n'\n",
    "            f'  - num_sigma Parameter: {federated_model_params[\"num_sigma\"]}\\n'\n",
    "            f'  - kappa_join Parameter: {federated_model_params[\"kappa_join\"]}\\n'\n",
    "            f'  - N_r Parameter: {federated_model_params[\"N_r\"]}')\n",
    "   \n",
    "\n",
    "            X = data.iloc[:, :-1].values\n",
    "            y = data.iloc[:, -1].values\n",
    "            client_raw_train, test_data, all_data = prepare_dataset(X, y, num_clients)\n",
    "\n",
    "\n",
    "            balance_techniques = ['random'] * int(proportion)\n",
    "\n",
    "\n",
    "            print(f\"Running experiment with {num_clients} clients and data configuration {proportion}\")\n",
    "            \n",
    "            if flag_profiler:\n",
    "                # Import profiling packages only if profiler is True\n",
    "                import cProfile\n",
    "                import yappi\n",
    "                try:\n",
    "                    # Try to load the memory_profiler extension if it's available\n",
    "                    get_ipython().run_line_magic('load_ext', 'memory_profiler')\n",
    "                except:\n",
    "                    print(\"Memory profiler not available.\")\n",
    "\n",
    "                print(f\"... with profiler\")\n",
    "                pr = cProfile.Profile()\n",
    "                pr.enable()\n",
    "                yappi.start()\n",
    "                \n",
    "                metrics = run_individual_experiment(federated_model_params=federated_model_params, \n",
    "                                                    local_model_params=local_model_params, \n",
    "                                                    num_clients=num_clients, num_rounds=num_rounds, \n",
    "                                                    client_raw_train=client_raw_train, test_data=test_data,\n",
    "                                                    balance_techniques=balance_techniques, test_clients=flag_test_clients)\n",
    "                \n",
    "                yappi.stop()\n",
    "                pr.disable()\n",
    "\n",
    "                pr.print_stats(sort='cumtime')\n",
    "                yappi.get_thread_stats().print_all()\n",
    "                yappi.get_func_stats().print_all()\n",
    "            else:\n",
    "                metrics = run_individual_experiment(federated_model_params=federated_model_params, \n",
    "                                                    local_model_params=local_model_params, \n",
    "                                                        num_clients=num_clients, num_rounds=num_rounds, \n",
    "                                                    client_raw_train=client_raw_train, test_data=test_data,\n",
    "                                                    balance_techniques=balance_techniques, test_clients=flag_test_clients)\n",
    "\n",
    "            #experiments.append((f\"num_clients_{num_clients}_sampling_{proportion}\", metrics))\n",
    "\n",
    "            #Construct a specific name for the saved file\n",
    "            file_name = f'experiment_metrics_num_clients_{num_clients}_rounds_{num_rounds}_proportions_{proportion}_num_sigma_{federated_model_params[\"num_sigma\"]}_kappa_join_{int(federated_model_params[\"kappa_join\"]*10)}_N_r_{federated_model_params[\"N_r\"]}_clusters_{federated_model_params[\"c_max\"]}_Fscore_{1000*metrics[-1][\"federated_model\"][\"binary\"][\"f1_score\"]:.0f}.pth'\n",
    "            file_path = os.path.join(results_dir, file_name)\n",
    "\n",
    "            #Save the experiments\n",
    "            torch.save(metrics, file_path)\n",
    "            print(f\"Saved experiments to {file_path}\")\n",
    "            \n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_metric(experiments, round_number):\n",
    "    # and each experiment's metrics contain the F1 score for the federated model\n",
    "    for experiment in experiments:\n",
    "        if experiment[1][-1]['round'] == int(round_number): #[1] is the experiment values, [0] is the name of the experiment, [-1] is the last round\n",
    "            return experiment[1][-1]['federated_model']['binary']['f1_score']\n",
    "    return None\n",
    "\n",
    "def run_parameterized_experiments(data, client_counts, proportions, num_rounds):\n",
    "    best_setting = None\n",
    "    best_f1_score = -float('inf')\n",
    "    all_experiments_metrics = []\n",
    "\n",
    "    for num_sigma in num_sigma_values:\n",
    "        for kappa_join in kappa_join_values:\n",
    "            for N_r in N_r_values:\n",
    "\n",
    "                    # Update the model parameters\n",
    "                    federated_model_params.update({\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r})\n",
    "                    local_model_params.update({\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r})\n",
    "\n",
    "                    # Run the experiment\n",
    "                    experiments = run_experiments(\n",
    "                        data=data,\n",
    "                        client_counts=client_counts,\n",
    "                        federated_model_params=federated_model_params, \n",
    "                        local_model_params=local_model_params, \n",
    "                        num_rounds=num_rounds, \n",
    "                        proportions=proportions, \n",
    "                        flag_profiler= False,\n",
    "                        flag_test_clients = False)\n",
    "\n",
    "\n",
    "                    # Store all experiments' metrics\n",
    "                    all_experiments_metrics.append(experiments)\n",
    "\n",
    "                    # Evaluate the F1 score of the 5th round\n",
    "                    f1_score = evaluate_metric(experiments, num_rounds)\n",
    "                    \n",
    "                    # Update the best setting if current setting's F1 score is better\n",
    "                    if f1_score and f1_score > best_f1_score:\n",
    "                        best_f1_score = f1_score\n",
    "                        best_setting = (num_sigma, kappa_join, N_r, proportions)\n",
    "\n",
    "    return best_setting, best_f1_score, all_experiments_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if flag_settings_experiment:\n",
    "    \n",
    "    #This code runs multiple experiments to deterime the best settings\n",
    "    best_setting, best_f1_score, all_experiments_metrics = run_parameterized_experiments(data, client_counts, data_config_indices, num_rounds)\n",
    "    print(\"Best Setting:\", best_setting)\n",
    "    print(\"Best F1 Score:\", best_f1_score)\n",
    "\n",
    "    # Save the best setting and all experiments' metrics\n",
    "    torch.save({\n",
    "        \"best_setting\": best_setting,\n",
    "        \"best_f1_score\": best_f1_score,\n",
    "        \"experiments_metrics\": all_experiments_metrics\n",
    "    }, 'experiment_results.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " *** Experiment details ***:\n",
      "  - Number of Clients: 3\n",
      "  - Number of Rounds: 31\n",
      "  - Number of Clusters: 1000\n",
      "  - Data dristribution proportions: 5\n",
      "  - num_sigma Parameter: 15\n",
      "  - kappa_join Parameter: 0.4\n",
      "  - N_r Parameter: 30\n",
      "Running experiment with 3 clients and data configuration 5\n",
      "--- Communication Round 1 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 792.0\n",
      "Number of local model clusters = 234\n",
      "Updated var_glo values: tensor(15.0599, device='cuda:0')\n",
      "Federated clusters after merging = 56\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 792.0\n",
      "Number of local model clusters = 186\n",
      "Updated var_glo values: tensor(15.3035, device='cuda:0')\n",
      "Federated clusters after merging = 106\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 792.0\n",
      "Number of local model clusters = 358\n",
      "Updated var_glo values: tensor(14.7185, device='cuda:0')\n",
      "Federated clusters after merging = 225\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.9259, device='cuda:0')\n",
      "tensor(14.8038, device='cuda:0')\n",
      "tensor(14.4251, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 1 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 13.6s\n",
      "--- Communication Round 2 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 473\n",
      "Updated var_glo values: tensor(15.1840, device='cuda:0')\n",
      "Federated clusters after merging = 426\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 436\n",
      "Updated var_glo values: tensor(14.7085, device='cuda:0')\n",
      "Federated clusters after merging = 753\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 606\n",
      "Updated var_glo values: tensor(14.3684, device='cuda:0')\n",
      "Federated clusters after merging = 1137\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.5771, device='cuda:0')\n",
      "tensor(14.1982, device='cuda:0')\n",
      "tensor(14.3342, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 2 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 35.8s\n",
      "--- Communication Round 3 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 1521\n",
      "Updated var_glo values: tensor(14.8651, device='cuda:0')\n",
      "Federated clusters after merging = 1949\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 1489\n",
      "Updated var_glo values: tensor(14.3773, device='cuda:0')\n",
      "Federated clusters after merging = 1973\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 1586\n",
      "Updated var_glo values: tensor(13.8853, device='cuda:0')\n",
      "Federated clusters after merging = 1976\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(13.6331, device='cuda:0')\n",
      "tensor(14.1364, device='cuda:0')\n",
      "tensor(13.8877, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 3 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 83.4s\n",
      "--- Communication Round 4 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2016\n",
      "Updated var_glo values: tensor(14.5743, device='cuda:0')\n",
      "Federated clusters after merging = 1977\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2007\n",
      "Updated var_glo values: tensor(14.5682, device='cuda:0')\n",
      "Federated clusters after merging = 1978\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2013\n",
      "Updated var_glo values: tensor(14.0758, device='cuda:0')\n",
      "Federated clusters after merging = 1979\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.1963, device='cuda:0')\n",
      "tensor(14.2059, device='cuda:0')\n",
      "tensor(13.8293, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 4 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 95.0s\n",
      "--- Communication Round 5 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2006\n",
      "Updated var_glo values: tensor(14.9529, device='cuda:0')\n",
      "Federated clusters after merging = 1982\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2017\n",
      "Updated var_glo values: tensor(14.5294, device='cuda:0')\n",
      "Federated clusters after merging = 1985\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2020\n",
      "Updated var_glo values: tensor(14.0878, device='cuda:0')\n",
      "Federated clusters after merging = 1987\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.0922, device='cuda:0')\n",
      "tensor(14.3094, device='cuda:0')\n",
      "tensor(13.8657, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 5 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 98.5s\n",
      "--- Communication Round 6 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2013\n",
      "Updated var_glo values: tensor(14.6848, device='cuda:0')\n",
      "Federated clusters after merging = 1991\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2026\n",
      "Updated var_glo values: tensor(14.4234, device='cuda:0')\n",
      "Federated clusters after merging = 1991\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2029\n",
      "Updated var_glo values: tensor(14.3338, device='cuda:0')\n",
      "Federated clusters after merging = 1994\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.4263, device='cuda:0')\n",
      "tensor(14.2909, device='cuda:0')\n",
      "tensor(14.2885, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 6 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 109.5s\n",
      "--- Communication Round 7 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2022\n",
      "Updated var_glo values: tensor(14.8396, device='cuda:0')\n",
      "Federated clusters after merging = 1996\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2023\n",
      "Updated var_glo values: tensor(15.1626, device='cuda:0')\n",
      "Federated clusters after merging = 1997\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2029\n",
      "Updated var_glo values: tensor(14.6909, device='cuda:0')\n",
      "Federated clusters after merging = 1997\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.4545, device='cuda:0')\n",
      "tensor(14.7329, device='cuda:0')\n",
      "tensor(14.8898, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 7 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 100.3s\n",
      "--- Communication Round 8 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2034\n",
      "Updated var_glo values: tensor(14.9968, device='cuda:0')\n",
      "Federated clusters after merging = 1997\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2015\n",
      "Updated var_glo values: tensor(15.4084, device='cuda:0')\n",
      "Federated clusters after merging = 1997\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2025\n",
      "Updated var_glo values: tensor(14.5763, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.1566, device='cuda:0')\n",
      "tensor(14.6862, device='cuda:0')\n",
      "tensor(14.8885, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 8 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 102.2s\n",
      "--- Communication Round 9 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2021\n",
      "Updated var_glo values: tensor(15.5345, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2018\n",
      "Updated var_glo values: tensor(14.7074, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2023\n",
      "Updated var_glo values: tensor(14.3718, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.6680, device='cuda:0')\n",
      "tensor(14.2487, device='cuda:0')\n",
      "tensor(14.2024, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 9 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Round 9: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.9457839115933364\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 97.0s\n",
      "--- Communication Round 10 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2026\n",
      "Updated var_glo values: tensor(14.7413, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2035\n",
      "Updated var_glo values: tensor(14.9295, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2025\n",
      "Updated var_glo values: tensor(14.3434, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.4479, device='cuda:0')\n",
      "tensor(14.0489, device='cuda:0')\n",
      "tensor(14.5364, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 10 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Round 9: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.9457839115933364\n",
      "\n",
      "Round 10: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9447513306134891\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 101.3s\n",
      "--- Communication Round 11 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2023\n",
      "Updated var_glo values: tensor(14.6833, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2014\n",
      "Updated var_glo values: tensor(14.5384, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2027\n",
      "Updated var_glo values: tensor(13.8858, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: tensor(14.0899, device='cuda:0')\n",
      "Updated var_glo values: tensor(14.0125, device='cuda:0')\n",
      "tensor(13.5586, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 11 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Round 9: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.9457839115933364\n",
      "\n",
      "Round 10: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9447513306134891\n",
      "\n",
      "Round 11: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9445368278057187\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 109.3s\n",
      "--- Communication Round 12 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2030\n",
      "Updated var_glo values: tensor(16.1421, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2023\n",
      "Updated var_glo values: tensor(15.3337, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2027\n",
      "Updated var_glo values: tensor(14.6556, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(15.0344, device='cuda:0')\n",
      "tensor(14.3147, device='cuda:0')tensor(14.6215, device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "--- End of Round 12 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Round 9: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.9457839115933364\n",
      "\n",
      "Round 10: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9447513306134891\n",
      "\n",
      "Round 11: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9445368278057187\n",
      "\n",
      "Round 12: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9442297279276428\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 110.4s\n",
      "--- Communication Round 13 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2023\n",
      "Updated var_glo values: tensor(15.2132, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2028\n",
      "Updated var_glo values: tensor(14.5733, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2036\n",
      "Updated var_glo values: tensor(13.9619, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(14.2796, device='cuda:0')\n",
      "Updated var_glo values: Updated var_glo values: tensor(13.6556, device='cuda:0')\n",
      "tensor(13.9545, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 13 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Round 9: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.9457839115933364\n",
      "\n",
      "Round 10: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9447513306134891\n",
      "\n",
      "Round 11: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9445368278057187\n",
      "\n",
      "Round 12: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9442297279276428\n",
      "\n",
      "Round 13: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.719626168224299, 'recall': 0.8020833333333334, 'f1_score': 0.7586206896551724}, ROC AUC: 0.9450190469700701\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 110.1s\n",
      "--- Communication Round 14 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2027\n",
      "Updated var_glo values: tensor(14.6984, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2028\n",
      "Updated var_glo values: tensor(14.8058, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2028\n",
      "Updated var_glo values: tensor(14.3220, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.4209, device='cuda:0')\n",
      "tensor(14.4701, device='cuda:0')\n",
      "tensor(14.0792, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 14 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Round 9: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.9457839115933364\n",
      "\n",
      "Round 10: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9447513306134891\n",
      "\n",
      "Round 11: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9445368278057187\n",
      "\n",
      "Round 12: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9442297279276428\n",
      "\n",
      "Round 13: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.719626168224299, 'recall': 0.8020833333333334, 'f1_score': 0.7586206896551724}, ROC AUC: 0.9450190469700701\n",
      "\n",
      "Round 14: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.719626168224299, 'recall': 0.8020833333333334, 'f1_score': 0.7586206896551724}, ROC AUC: 0.9448943935450591\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 109.6s\n",
      "--- Communication Round 15 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2027\n",
      "Updated var_glo values: tensor(14.9083, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2021\n",
      "Updated var_glo values: tensor(14.6187, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2029\n",
      "Updated var_glo values: tensor(14.4109, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.5401, device='cuda:0')\n",
      "tensor(14.3903, device='cuda:0')\n",
      "tensor(14.3070, device='cuda:0')\n",
      "\n",
      "\n",
      "--- End of Round 15 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9973139988062217, 'precision': 0.36363636363636365, 'recall': 0.7916666666666666, 'f1_score': 0.49836065573770494}, ROC AUC: 0.9690837524472737\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9978582212703205, 'precision': 0.43010752688172044, 'recall': 0.8333333333333334, 'f1_score': 0.5673758865248227}, ROC AUC: 0.9756820493206251\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.9982971103542713, 'precision': 0.4968944099378882, 'recall': 0.8333333333333334, 'f1_score': 0.622568093385214}, ROC AUC: 0.9667720313251035\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9989642217618764, 'precision': 0.6504065040650406, 'recall': 0.8333333333333334, 'f1_score': 0.730593607305936}, ROC AUC: 0.9558475919999061\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9990695551420246, 'precision': 0.6869565217391305, 'recall': 0.8229166666666666, 'f1_score': 0.7488151658767772}, ROC AUC: 0.9515448964817875\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.6814159292035398, 'recall': 0.8020833333333334, 'f1_score': 0.7368421052631579}, ROC AUC: 0.9495213161936248\n",
      "\n",
      "Round 7: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.947498468622141\n",
      "\n",
      "Round 8: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9466532799329417\n",
      "\n",
      "Round 9: Metrics: {'accuracy': 0.9991046662687406, 'precision': 0.7102803738317757, 'recall': 0.7916666666666666, 'f1_score': 0.7487684729064039}, ROC AUC: 0.9457839115933364\n",
      "\n",
      "Round 10: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9447513306134891\n",
      "\n",
      "Round 11: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.7238095238095238, 'recall': 0.7916666666666666, 'f1_score': 0.7562189054726368}, ROC AUC: 0.9445368278057187\n",
      "\n",
      "Round 12: Metrics: {'accuracy': 0.9991222218320986, 'precision': 0.7129629629629629, 'recall': 0.8020833333333334, 'f1_score': 0.7549019607843137}, ROC AUC: 0.9442297279276428\n",
      "\n",
      "Round 13: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.719626168224299, 'recall': 0.8020833333333334, 'f1_score': 0.7586206896551724}, ROC AUC: 0.9450190469700701\n",
      "\n",
      "Round 14: Metrics: {'accuracy': 0.9991397773954567, 'precision': 0.719626168224299, 'recall': 0.8020833333333334, 'f1_score': 0.7586206896551724}, ROC AUC: 0.9448943935450591\n",
      "\n",
      "Round 15: Metrics: {'accuracy': 0.9991748885221726, 'precision': 0.7289719626168224, 'recall': 0.8125, 'f1_score': 0.7684729064039408}, ROC AUC: 0.945167330507978\n",
      "\n",
      "Saved experiment to .Results/mid_experiment_15_4_30_3_5_1000.pth\n",
      "Round time was 101.8s\n",
      "--- Communication Round 16 ---\n",
      "Client 1: {0: 660, 1: 132}\n",
      "Client 2: {0: 660, 1: 132}\n",
      "Client 3: {0: 660, 1: 132}\n",
      "Test Set: {0: 56866, 1: 96}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 58846 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 59338\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "\n",
      " Updating agreggated model with client 1\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2032\n",
      "Updated var_glo values: tensor(15.3021, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 2\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2023\n",
      "Updated var_glo values: tensor(14.8932, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      " Updating agreggated model with client 3\n",
      "Num of samples in global statistics 794.0\n",
      "Number of local model clusters = 2024\n",
      "Updated var_glo values: tensor(14.2404, device='cuda:0')\n",
      "Federated clusters after merging = 1998\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: Updated var_glo values: Updated var_glo values: tensor(14.5108, device='cuda:0')\n",
      "tensor(14.3012, device='cuda:0')\n",
      "tensor(13.9134, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# List of client counts and data configuration indices\n",
    "client_counts = [3, 10]\n",
    "\n",
    "# Number of communication rounds\n",
    "num_rounds = 31\n",
    "\n",
    "proportions = [5]\n",
    "\n",
    "# Model parameters\n",
    "local_model_params = {\n",
    "    \"feature_dim\": feature_dim,\n",
    "    \"num_classes\": 2,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 15,\n",
    "    \"kappa_join\": 0.4,\n",
    "    \"S_0\": 1e-10,\n",
    "    \"N_r\": 30,\n",
    "    \"c_max\": 1000,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "federated_model_params = {\n",
    "    \"feature_dim\": feature_dim,\n",
    "    \"num_classes\": 2,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 15,\n",
    "    \"kappa_join\": 0.4,\n",
    "    \"S_0\": 1e-10,\n",
    "    \"N_r\": 30,\n",
    "    \"c_max\": 1000,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "if flag_settings_experiment:\n",
    "    # Update the model parameters with the best setting\n",
    "    federated_model_params.update({\n",
    "        \"num_sigma\": best_setting[0],\n",
    "        \"kappa_join\": best_setting[1],\n",
    "        \"N_r\": best_setting[2]\n",
    "    })\n",
    "\n",
    "    local_model_params.update({\n",
    "        \"num_sigma\": best_setting[0],\n",
    "        \"kappa_join\": best_setting[1],\n",
    "        \"N_r\": best_setting[2]\n",
    "    })\n",
    "\n",
    "    # Set the number of rounds and proportion with the best setting\n",
    "    proportion = best_setting[3]\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Run the experiments with the best setting for 30 rounds\n",
    "experiments = run_experiments(\n",
    "            data=data, \n",
    "            client_counts=client_counts,\n",
    "            federated_model_params=federated_model_params, \n",
    "            local_model_params=local_model_params, \n",
    "            num_rounds=num_rounds, \n",
    "            proportions=proportions, \n",
    "            flag_profiler=False,\n",
    "            flag_test_clients = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"experiment_metrics_num_clients_3_rounds_31_proportions_5_num_sigma_15_kappa_join_4_N_r_30_clusters_300_Fscore_778.pth\"\n",
    "experiments = torch.load(f\".Results/{name}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_metrics = []\n",
    "figs_clusters = []\n",
    "experiment_name = []\n",
    "rounds_max = 30\n",
    "if len(name) > 40:\n",
    "        metrics = experiments\n",
    "        rounds = [m['round'] for m in metrics]\n",
    "        if rounds[-1] > rounds_max:\n",
    "             rounds = rounds[:rounds_max]\n",
    "             metrics = metrics[:rounds_max]\n",
    "        # Plot and collect figures\n",
    "       \n",
    "        figs_metrics.append(plot_metric_data(metrics, ['f1_score', 'precision', 'recall'], rounds, ''))\n",
    "        figs_clusters.append(plot_cluster_data(metrics, rounds))\n",
    "        print(f\"{100*metrics[-1]['federated_model']['binary']['f1_score']:.0f}\")\n",
    "else:\n",
    "        rounds = [m['round'] for m in experiments]\n",
    "        if rounds[-1] > rounds_max:\n",
    "             rounds = rounds[:rounds_max]\n",
    "             experiments = experiments[:rounds_max]\n",
    "        # Plot and collect figures\n",
    "        figs_metrics.append(plot_metric_data(experiments, ['f1_score', 'precision', 'recall'], rounds,\"\", legend=experiments))\n",
    "        figs_clusters.append(plot_cluster_data(experiments, rounds, legend=experiments))\n",
    "        print(f\"{100*experiments[-1]['federated_model']['binary']['f1_score']:.0f}\")\n",
    "\n",
    "os.makedirs(\".Images\", exist_ok=True)  # Create the directory to save the images if it doesn't exist\n",
    "\n",
    "# Save figures from fig_metrics\n",
    "for i, figure in enumerate(figs_metrics):\n",
    "    save_path = f\".Images/credit_fraud_metrics_{name}.pdf\"\n",
    "    save_figure(figure, save_path, \"pdf\")\n",
    "\n",
    "# Save figures from fig_clusters\n",
    "for i, figure in enumerate(figs_clusters):\n",
    "    save_path = f\".Images/credit_fraud_clusters_{name}.pdf\"\n",
    "    save_figure(figure, save_path, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract settings from filename\n",
    "def extract_settings(filename):\n",
    "    pattern = r\"(num_clients|rounds|proportions|num_sigma|kappa_join|N_r|clusters)_([0-9]+)\"\n",
    "    matches = re.findall(pattern, filename)\n",
    "    return {match[0]: int(match[1]) for match in matches}\n",
    "\n",
    "# Load all experiments and group by settings\n",
    "experiments_by_settings = {}\n",
    "directory = \".Results\"\n",
    "round_of_interest = 30  # Specify the round of interest\n",
    "num_experiments = 3  # Specify the number of experiments required for each setting\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"experiment_metrics_\"):\n",
    "        settings = extract_settings(filename)\n",
    "        settings_key = tuple(sorted(settings.items()))\n",
    "\n",
    "        if settings_key not in experiments_by_settings:\n",
    "            experiments_by_settings[settings_key] = []\n",
    "\n",
    "        experiment_data = torch.load(f\"{directory}/{filename}\")\n",
    "        experiments_by_settings[settings_key].append(experiment_data)\n",
    "\n",
    "# Calculate average and std of metrics at the specified round for each settings group\n",
    "metrics_by_settings = {}\n",
    "\n",
    "for settings, experiments in experiments_by_settings.items():\n",
    "    if len(experiments) >= num_experiments:\n",
    "        f1_scores, precisions, recalls, roc_aucs = [], [], [], []\n",
    "\n",
    "        for experiment in experiments:\n",
    "            if len(experiment) >= round_of_interest:\n",
    "                round_data = experiment[round_of_interest - 1]['federated_model']\n",
    "                f1_scores.append(100*round_data['binary']['f1_score'])\n",
    "                precisions.append(100*round_data['binary']['precision'])\n",
    "                recalls.append(100*round_data['binary']['recall'])\n",
    "                roc_aucs.append(round_data['roc_auc'])\n",
    "\n",
    "        metrics_by_settings[settings] = {\n",
    "            'avg_f1': np.mean(f1_scores), 'std_f1': np.std(f1_scores),\n",
    "            'avg_precision': np.mean(precisions), 'std_precision': np.std(precisions),\n",
    "            'avg_recall': np.mean(recalls), 'std_recall': np.std(recalls),\n",
    "            'avg_roc_auc': np.mean(roc_aucs), 'std_roc_auc': np.std(roc_aucs)\n",
    "        }\n",
    "\n",
    "for settings, metrics in metrics_by_settings.items():\n",
    "    settings_str = ', '.join(f\"{key}={value}\" for key, value in settings)\n",
    "    print(f\"Settings: {settings_str} -> Average F1 Score: {metrics['avg_f1']:.4f}, Standard Deviation: {metrics['std_f1']:.4f}, \"\n",
    "          f\"Average Precision: {metrics['avg_precision']:.4f}, Standard Deviation: {metrics['std_precision']:.4f}, \"\n",
    "          f\"Average Recall: {metrics['avg_recall']:.4f}, Standard Deviation: {metrics['std_recall']:.4f}, \"\n",
    "          f\"Average ROC AUC: {metrics['avg_roc_auc']:.4f}, Standard Deviation: {metrics['std_roc_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(data):\n",
    "    latex_table = \"\\\\begin{table}[!t]\\n\"\n",
    "    latex_table += \"\\\\centering\\n\"\n",
    "    latex_table += \"\\\\setlength{\\\\tabcolsep}{4pt}\\n\"  # Changed tabcolsep to 5pt\n",
    "    latex_table += \"\\\\scriptsize\\n\"\n",
    "    latex_table += \"\\\\caption{Results of the Credit Card Fraud Detection}\\n\"\n",
    "    latex_table += \"\\\\begin{tabular}{ll|cccccccc}\\n\"\n",
    "    latex_table += \"\\\\toprule\\n\"\n",
    "    # Changed header row to use bold font and mathematical symbols where necessary\n",
    "    latex_table += \"\\\\bf{Data} & $\\\\mathbf{\\\\kappa}_c$ & \\\\multicolumn{2}{c}{\\\\bf{Precision}(\\\\%)$\\\\uparrow$} & \\\\multicolumn{2}{c}{\\\\bf{Recall}(\\\\%)$\\\\uparrow$} & \\\\multicolumn{2}{c}{\\\\bf{F1 score}(\\\\%)$\\\\uparrow$} & \\\\multicolumn{2}{c}{\\\\bf{ROC AUC}$\\\\uparrow$} \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\cmidrule(lr){3-4} \\\\cmidrule(lr){5-6} \\\\cmidrule(lr){7-8} \\\\cmidrule(lr){9-10}\\n\"\n",
    "    # Changed number headings to bold\n",
    "    latex_table += \"&  & \\\\bf{3} & \\\\bf{10} & \\\\bf{3} & \\\\bf{10} & \\\\bf{3} & \\\\bf{10} & \\\\bf{3} & \\\\bf{10} \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\midrule\\n\"\n",
    "\n",
    "    # Find the best F1 score for 3 clients and 10 clients\n",
    "    best_f1_3 = max(metrics['avg_f1'] for settings, metrics in data.items() if 'avg_f1' in metrics and dict(settings).get('num_clients') == 3)\n",
    "    best_f1_10 = max(metrics['avg_f1'] for settings, metrics in data.items() if 'avg_f1' in metrics and dict(settings).get('num_clients') == 10)\n",
    "\n",
    "\n",
    "    # Sort and group data by settings, excluding num_clients\n",
    "    grouped_data = {}\n",
    "    for settings, metrics in data.items():\n",
    "        # Create a key for grouping, excluding 'num_clients'\n",
    "        group_key = tuple((k, v) for k, v in settings if k != 'num_clients')\n",
    "        if group_key not in grouped_data:\n",
    "            grouped_data[group_key] = {}\n",
    "        num_clients = dict(settings).get('num_clients')\n",
    "        grouped_data[group_key][num_clients] = metrics\n",
    "\n",
    "    # Sort grouped data by proportions and then by clusters\n",
    "    sorted_grouped_data = sorted(grouped_data.items(), key=lambda x: (dict(x[0]).get('proportions', 0), dict(x[0]).get('clusters', 0)))\n",
    "   \n",
    "    last_proportion = None\n",
    "    for settings, client_data in sorted_grouped_data:\n",
    "        proportions = dict(settings).get('proportions', 'N/A')\n",
    "        \n",
    "        # Add a horizontal line when the proportion setting changes\n",
    "        if last_proportion is not None and last_proportion != proportions:\n",
    "            latex_table += \"\\\\hline\\n\"\n",
    "        last_proportion = proportions\n",
    "        metrics_3_clients = client_data.get(3)\n",
    "        metrics_10_clients =  client_data.get(10)\n",
    "\n",
    "        # Function to format metric value or empty placeholder\n",
    "        format_metric = lambda val: f\"$ {val:.1f} $\" if val is not None else \"$ $\"\n",
    "        format_roc_auc = lambda val: f\"$ {val:.3f} $\" if val is not None else \"$ $\"\n",
    "        \n",
    "        # Extract and format the dataset value\n",
    "        proportions = dict(settings).get('proportions', 'N/A')\n",
    "        dataset = f\"{proportions}:1\" if proportions != 'N/A' else \"N/A\"\n",
    "        clusters = 2*dict(settings).get('clusters', 'N/A')\n",
    "\n",
    "\n",
    "        # Extract and format metrics for 3 clients\n",
    "        if metrics_3_clients:\n",
    "            avg_precision_3 = format_metric(metrics_3_clients['avg_precision'])\n",
    "            avg_recall_3 = format_metric(metrics_3_clients['avg_recall'])\n",
    "            avg_f1_3 = format_metric(metrics_3_clients['avg_f1'])\n",
    "            avg_roc_auc_3 = format_roc_auc(metrics_3_clients['avg_roc_auc'])\n",
    "        else:\n",
    "            avg_precision_3 = avg_recall_3 = avg_f1_3 = avg_roc_auc_3 = \"$ $\"\n",
    "\n",
    "        # Extract and format metrics for 10 clients\n",
    "        if metrics_10_clients:\n",
    "            avg_precision_10 = format_metric(metrics_10_clients['avg_precision'])\n",
    "            avg_recall_10 = format_metric(metrics_10_clients['avg_recall'])\n",
    "            avg_f1_10 = format_metric(metrics_10_clients['avg_f1'])\n",
    "            avg_roc_auc_10 = format_roc_auc(metrics_10_clients['avg_roc_auc'])\n",
    "        else:\n",
    "            avg_precision_10 = avg_recall_10 = avg_f1_10 = avg_roc_auc_10 = \"$ $\"\n",
    "            \n",
    "        # Bold the best F1 scores\n",
    "        avg_f1_3 = f\"$\\\\textbf{{{metrics_3_clients['avg_f1']:.1f}}}$\" if metrics_3_clients and metrics_3_clients['avg_f1'] == best_f1_3 else f\"${metrics_3_clients['avg_f1']:.1f}$\" if metrics_3_clients else \"$ $\"\n",
    "        avg_f1_10 = f\"$\\\\textbf{{{metrics_10_clients['avg_f1']:.1f}}}$\" if metrics_10_clients and metrics_10_clients['avg_f1'] == best_f1_10 else f\"${metrics_10_clients['avg_f1']:.1f}$\" if metrics_10_clients else \"$ $\"\n",
    "\n",
    "        latex_table += f\"    {dataset} & {clusters} & {avg_precision_3} & {avg_precision_10} & {avg_recall_3} & {avg_recall_10} & {avg_f1_3} & {avg_f1_10} & {avg_roc_auc_3} & {avg_roc_auc_10}\\\\\\\\\\n\"\n",
    "\n",
    "    latex_table += \"\\\\bottomrule\\n\"\n",
    "    latex_table += \"\\\\multicolumn{10}{p{0.95\\linewidth}}{\\\\tiny The first column (Data) shown the proportion of non-fraud to fraud samples in the training data, which was selected by random undersampling. The second column ($\\kappa_c$) shows the maximum number of clusters of the federated model, before pruning was used. The evaluation metrics shown are averages for 3 repetitions.}\"\n",
    "    latex_table += \"\\\\end{tabular}\\n\"\n",
    "    latex_table += \"\\\\label{tab:credit_fraud}\\n\"\n",
    "    latex_table += \"\\\\end{table}\\n\"\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "print(generate_latex_table(metrics_by_settings))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
